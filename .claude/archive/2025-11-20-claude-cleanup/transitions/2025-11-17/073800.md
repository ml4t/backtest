# Session Transition: Integrated ML Data + Risk Management Plan

**Date**: 2025-11-17T07:38:00Z
**Session Type**: Planning - Plan Integration & Merger
**Status**: Phase 0 Complete, Merge Analysis Complete, Ready for Final Deliverables
**Next Session**: Create integrated state.json and implementation plan

---

## Session Summary

Successfully integrated two large feature sets (ML Data Architecture + Risk Management) into a single coherent implementation plan, achieving 46% task reduction and 35% timeline reduction.

**Key Achievement**: Identified critical dependency - Risk Management requires ML Data Architecture foundation (RiskContext needs features from enhanced MarketEvent).

---

## What Was Accomplished

### 1. ✅ ML Data Architecture Analysis (Complete)
**Files Created**:
- `ML_DATA_ARCHITECTURE_PROPOSAL.md` (11,000 words)
- `ML_DATA_ARCHITECTURE_TASKS.md` (27 tasks, 320 hours)
- `PHASE_0_COMPLETION_SUMMARY.md`
- `tests/benchmarks/benchmark_event_loop.py`

**External Review**: Conducted via reasoning-specialist agent
- **Verdict**: CONDITIONALLY APPROVED
- **Critical fixes identified**:
  - Event generation: use group_by not filter (10-50x speedup)
  - Signal timing validation (prevent look-ahead bias)
  - Comprehensive data validation (all rows, not sample)
  - Realistic performance targets (10-30k events/sec)

### 2. ✅ Merge Analysis (Complete)
**File Created**: `MERGE_ANALYSIS.md`

**Key Findings**:
- **Tasks**: 50 (down from 93) - 46% reduction
- **Timeline**: 10 weeks (down from 15.5) - 35% reduction
- **Effort**: 420 hours (down from 600) - 30% reduction

**Critical Dependency Discovered**:
```python
# Risk Management needs this:
@dataclass
class RiskContext:
    features: dict[str, float]      # From MarketEvent.indicators
    market_features: dict[str, float]  # From MarketEvent.context

# But current MarketEvent only has:
class MarketEvent:
    signals: dict[str, float]  # ✅ Has this
    # ❌ Missing indicators dict
    # ❌ Missing context dict

# ML Data Architecture adds these:
class MarketEvent:  # Enhanced
    signals: dict[str, float]
    indicators: dict[str, float]   # ✅ Will add
    context: dict[str, float]      # ✅ Will add
```

**Conclusion**: ML Data foundation MUST come before Risk Management.

### 3. ✅ Integrated Phase Structure (Defined)

**Phase 1: ML Data Foundation** (3 weeks, 110 hours)
- Enhanced MarketEvent (signals, indicators, context)
- PolarsDataFeed (lazy loading, chunking, validation)
- FeatureProvider (unified for ML + Risk)
- Configuration system (YAML/JSON)
- Performance optimizations (group_by, caching)

**Phase 2: Risk Management Core** (2 weeks, 85 hours)
- RiskContext/RiskDecision/RiskRule
- RiskManager with engine integration
- Basic risk rules
- Position monitoring

**Phase 3: Advanced Features** (3 weeks, 120 hours - parallel)
- Track A: Trade recording enhancements
- Track B: Advanced risk rules (volatility-scaled, regime-dependent)
- Track C: Enhanced slippage models

**Phase 4: Integration & Documentation** (2 weeks, 100 hours)
- Unified examples (ML + Risk together)
- Complete documentation
- Performance benchmarks

---

## What Still Needs to Be Done

### Immediate Next Steps (Next Session)

#### 1. Create Integrated state.json
**Location**: `.claude/work/009_risk_management_exploration/state.json`

**Requirements**:
- **50 tasks** total (merged from 93)
- Proper dependencies (Phase 1 → Phase 2 → Phase 3 → Phase 4)
- Clear task sizing (2-8 hours each)
- Comprehensive acceptance criteria
- Priority levels (critical, high, medium, low)
- `parallel_batch` field for Phase 3 tracks

**Key Tasks to Include** (first 10):

1. **TASK-INT-001**: Enhanced MarketEvent with signals, indicators, context dicts (4h, critical)
2. **TASK-INT-002**: FeatureProvider interface (4h, critical)
3. **TASK-INT-003**: PolarsDataFeed core implementation (16h, critical)
4. **TASK-INT-004**: Event generation optimization - group_by vs filter (8h, critical)
5. **TASK-INT-005**: Signal timing validation (6h, critical)
6. **TASK-INT-006**: Comprehensive data validation (10h, critical)
7. **TASK-INT-007**: Configuration schema and loader (12h, high)
8. **TASK-INT-008**: Polars optimizations (compression, categorical, partitioning) (8h, high)
9. **TASK-INT-009**: Unified Strategy API (simple + batch modes) (8h, high)
10. **TASK-INT-010**: Engine integration with PolarsDataFeed (12h, high)

**Template for Each Task**:
```json
{
  "id": "TASK-INT-XXX",
  "phase": "phase_1|phase_2|phase_3|phase_4",
  "title": "Clear task title",
  "description": "Detailed description of what needs to be done",
  "type": "foundation|feature|integration|testing|documentation",
  "status": "pending",
  "dependencies": ["TASK-INT-YYY"],
  "files": ["src/ml4t/backtest/..."],
  "acceptance_criteria": [
    "Specific, testable criteria",
    "Each criterion is verifiable"
  ],
  "estimated_hours": 4,
  "priority": "critical|high|medium|low",
  "parallel_batch": "batch_A|batch_B|batch_C",  // Only for Phase 3
  "notes": "Additional context or warnings"
}
```

**Phase 3 Parallel Batches**:
- `batch_A`: Trade recording tasks (can run independently)
- `batch_B`: Advanced risk rules (can run independently)
- `batch_C`: Enhanced slippage (can run independently)

#### 2. Create INTEGRATED_IMPLEMENTATION_PLAN.md
**Location**: `.claude/work/009_risk_management_exploration/INTEGRATED_IMPLEMENTATION_PLAN.md`

**Sections**:

**1. Executive Summary**
- Project overview
- Why merge (dependency + efficiency)
- Timeline and effort estimates
- Success metrics

**2. Merged Architecture**
- How ML Data and Risk Management work together
- Data flow: PolarsDataFeed → MarketEvent → Strategy + RiskManager
- Component interactions
- Shared infrastructure

**3. Phase Breakdown**
- Phase 1: ML Data Foundation (detailed)
- Phase 2: Risk Management Core (detailed)
- Phase 3: Advanced Features (detailed with parallel tracks)
- Phase 4: Integration & Documentation (detailed)

**4. Task Execution Strategy**
- Critical path
- Parallel execution opportunities
- Dependencies and sequencing
- Quality gates

**5. Technical Specifications**
- Enhanced MarketEvent schema
- PolarsDataFeed design
- FeatureProvider interface
- RiskContext/RiskManager architecture
- Configuration schema

**6. Performance Targets**
- Throughput: 10-30k events/sec
- Memory: <2 GB for 250 symbols × 1 year
- Backtest time: 2-5 minutes
- Optimization techniques

**7. Quality Assurance**
- Testing strategy (unit, integration, benchmark)
- Code quality standards
- Documentation requirements
- Performance validation

**8. Risk Assessment**
- Technical risks and mitigations
- Integration risks
- Performance risks
- Timeline risks

**9. Examples and Use Cases**
- Top 25 ML strategy with risk management
- Complete workflow demonstration
- Configuration examples

**10. Success Criteria**
- Functional completeness
- Performance targets met
- Integration validated
- Documentation complete

#### 3. Update Work Unit Metadata
**File**: `.claude/work/009_risk_management_exploration/metadata.json`

**Updates Needed**:
```json
{
  "name": "009_risk_management_exploration",
  "updated_at": "2025-11-17T07:40:00Z",
  "phase": "planning_complete",
  "status": "ready_for_implementation",
  "deliverables": {
    "planning": {
      "state.json": "50 integrated tasks",
      "INTEGRATED_IMPLEMENTATION_PLAN.md": "Comprehensive merged plan",
      "MERGE_ANALYSIS.md": "Integration analysis and justification"
    }
  },
  "metrics": {
    "total_tasks": 50,
    "total_hours": 420,
    "total_weeks": 10,
    "phases": 4,
    "task_reduction": "46% (from 93)",
    "timeline_reduction": "35% (from 15.5 weeks)"
  }
}
```

---

## Key Decisions Made

### 1. Dependency Order
**Decision**: ML Data Architecture foundation MUST come before Risk Management
**Rationale**: RiskContext requires features/indicators from enhanced MarketEvent
**Impact**: Prevents integration failures, ensures coherent architecture

### 2. Merged vs Separate
**Decision**: Merge into single plan
**Rationale**:
- Eliminates 46% duplication
- Faster delivery (35% timeline reduction)
- Better integration (designed together)
- Simplified maintenance (single codebase)

### 3. Phase Structure
**Decision**: 4 phases with Phase 3 having parallel tracks
**Rationale**:
- Phase 1-2: Sequential (dependencies)
- Phase 3: Parallel execution for efficiency
- Phase 4: Integration validates everything

### 4. Task Granularity
**Decision**: 2-8 hour tasks (50 total)
**Rationale**:
- Manageable units of work
- Clear progress tracking
- Parallel execution opportunities
- Easy to estimate and schedule

---

## Technical Context for Next Session

### Current State of Codebase

**MarketEvent** (needs enhancement):
```python
# File: src/ml4t/backtest/core/event.py (line 45-88)
class MarketEvent(Event):
    signals: dict[str, float] | None = None  # ✅ Has signals
    # ❌ Need to add:
    # indicators: dict[str, float] = field(default_factory=dict)
    # context: dict[str, float] = field(default_factory=dict)
```

**DataFeed** (current implementation):
```python
# File: src/ml4t/backtest/data/feed.py
# Has: ParquetDataFeed (basic)
# Need: PolarsDataFeed with:
#   - Lazy loading (scan_parquet not read_parquet)
#   - Monthly chunking
#   - group_by iteration (not filter loop)
#   - Comprehensive validation
#   - Signal timing checks
```

**Strategy** (needs unified API):
```python
# File: src/ml4t/backtest/strategy/base.py
# Current: Simple on_market_data() callback
# Need: Dual mode API:
#   - on_market_data(event) for simple strategies
#   - on_timestamp_batch(timestamp, batch, context) for multi-asset
```

### Performance Optimizations Required

**Critical Fix** (10-50x speedup):
```python
# BAD (current pattern in some places):
for ts in timestamps:
    rows = df.filter(pl.col("timestamp") == ts)  # O(T×N)

# GOOD (required pattern):
for (ts, group) in df.group_by("timestamp", maintain_order=True):
    # O(N) - single pass
```

**Validation Required**:
```python
# Signal timing validation (prevent look-ahead):
assert signal.timestamp <= first_use_timestamp

# Data quality (check ALL rows):
duplicates = df.group_by(['timestamp', 'symbol']).len()
assert (duplicates['len'] == 1).all()

# Price sanity:
assert (df['high'] >= df['low']).all()
assert (df['open'].is_between(df['low'], df['high'])).all()
```

---

## Files Modified This Session

**Created**:
- `.claude/work/009_risk_management_exploration/ML_DATA_ARCHITECTURE_PROPOSAL.md`
- `.claude/work/009_risk_management_exploration/ML_DATA_ARCHITECTURE_TASKS.md`
- `.claude/work/009_risk_management_exploration/PHASE_0_COMPLETION_SUMMARY.md`
- `.claude/work/009_risk_management_exploration/MERGE_ANALYSIS.md`
- `tests/benchmarks/benchmark_event_loop.py`

**Updated**:
- `.claude/work/ACTIVE_WORK` (set to `009_risk_management_exploration`)

**To Create Next**:
- `.claude/work/009_risk_management_exploration/state.json` (integrated)
- `.claude/work/009_risk_management_exploration/INTEGRATED_IMPLEMENTATION_PLAN.md`
- `.claude/work/009_risk_management_exploration/metadata.json` (updated)

---

## Reference Information

### Existing Plans to Reference

**ML Data Architecture**:
- Proposal: `ML_DATA_ARCHITECTURE_PROPOSAL.md` (sections 3-7 have detailed specs)
- Tasks: `ML_DATA_ARCHITECTURE_TASKS.md` (27 tasks with full details)
- Merge analysis: `MERGE_ANALYSIS.md` (eliminated duplication documented)

**Risk Management**:
- Current state: `state.json` (66 tasks, will be source for Phase 2-4 tasks)
- Implementation plan: `implementation-plan.md` (original risk management plan)

### Task Numbering Scheme

Use `TASK-INT-XXX` for integrated tasks:
- `001-015`: Phase 1 (ML Data Foundation) - critical priority
- `016-025`: Phase 2 (Risk Management Core) - high priority
- `026-040`: Phase 3 (Advanced Features) - medium priority, parallel batches
- `041-050`: Phase 4 (Integration & Docs) - varies

### Estimated Task Distribution

- **Phase 1**: ~15 tasks (ML Data Foundation)
- **Phase 2**: ~10 tasks (Risk Management Core)
- **Phase 3**: ~15 tasks (Advanced Features, 3 parallel tracks)
- **Phase 4**: ~10 tasks (Integration & Documentation)
- **Total**: ~50 tasks

---

## Next Session Commands

```bash
# 1. Continue work on this work unit
cd /home/stefan/ml4t/software/backtest
cat .claude/work/ACTIVE_WORK
# Should show: 009_risk_management_exploration

# 2. Read merge analysis for context
cat .claude/work/009_risk_management_exploration/MERGE_ANALYSIS.md

# 3. Reference existing plans
ls -la .claude/work/009_risk_management_exploration/

# 4. Create integrated state.json
# Use Write tool to create comprehensive state.json with 50 tasks

# 5. Create INTEGRATED_IMPLEMENTATION_PLAN.md
# Use Write tool with full implementation plan

# 6. Update metadata.json
# Use Edit tool to update metrics

# 7. Begin implementation
/workflow:next
# This will start TASK-INT-001 (Enhanced MarketEvent)
```

---

## Key Insights for Next Developer

1. **Foundation First**: Phase 1 (ML Data) must complete before Phase 2 (Risk). Don't try to parallelize these.

2. **Performance Critical**: The group_by optimization is not optional - it's a 10-50x difference. Implement it correctly in TASK-INT-004.

3. **Validation Essential**: Signal timing validation (TASK-INT-005) prevents look-ahead bias. This is a correctness issue, not just nice-to-have.

4. **Unified API**: The Strategy API merge (TASK-INT-009) serves both simple and multi-asset use cases. Keep it clean and auto-detect mode.

5. **Phase 3 Parallelization**: The three tracks in Phase 3 are truly independent and should be executed in parallel for efficiency.

6. **Example is Key**: The unified example (Phase 4) validates that both systems work together. Don't skip this.

---

## Success Metrics

**Planning Success** (This Session):
- ✅ Identified critical dependency (Risk needs ML Data)
- ✅ Eliminated 46% of duplicate tasks
- ✅ Reduced timeline by 35%
- ✅ Created coherent phase structure
- ✅ Documented merge rationale

**Implementation Success** (Next Sessions):
- [ ] All 50 tasks completed
- [ ] Performance targets met (10-30k events/sec, <2GB memory)
- [ ] Integration validated (ML + Risk working together)
- [ ] Documentation complete
- [ ] Example notebook executable and clear

---

## Questions to Clarify (If Any)

None at this time. The plan is clear and ready for execution.

---

**Status**: ✅ Ready for Handoff
**Next Action**: Create state.json and INTEGRATED_IMPLEMENTATION_PLAN.md
**Priority**: High - Implementation can begin immediately after
**Confidence**: High - All dependencies resolved, architecture validated

---

**Session End**: 2025-11-17T07:38:00Z
**Token Usage**: ~127k / 200k (64% used)
**Recommended Next Session**: Fresh context for clean state.json creation
