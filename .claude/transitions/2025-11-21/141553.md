# Handoff: 2025-11-21 14:15:53 UTC

## Active Work
Fixing validation tests after ml4t.backtest API migration from event-driven to callback-based architecture.

## Current State

**Test Results**: **142 passed, 12 failed, 2 skipped** (91% passing)

**What Was Fixed**:
1. ✅ Created `tests/validation/conftest.py` - Auto-skips tests when optional dependencies missing
2. ✅ Deleted 3 obsolete test files using removed old event-driven API
3. ✅ Fixed critical VectorBT wrapper bug in `tests/validation/common/engine_wrappers.py:290-302`

**VectorBT Wrapper Fix** (lines 290-302):
```python
if exits is not None:
    # User provided explicit exits
    exits_aligned = pd.Series(exits.values, index=ohlcv.index)
else:
    # No explicit exits: generate exits one bar before subsequent entries
    # This avoids VectorBT's conflict resolution and matches ml4t.backtest's "close on next entry" behavior
    exits_aligned = pd.Series([False] * len(entries_aligned), index=ohlcv.index)
    entry_indices = entries_aligned[entries_aligned].index.tolist()

    # For each entry after the first, place exit signal one bar before
    for i in range(1, len(entry_indices)):
        entry_time = entry_indices[i]
        idx_pos = ohlcv.index.get_loc(entry_time)
        if idx_pos > 0:
            exits_aligned.iloc[idx_pos - 1] = True
```

**Impact**: VectorBT now produces 20 trades (vs ml4t.backtest's 19), with ~0.6% PnL difference. This is the closest approximation possible given VectorBT's execution model.

## Root Cause Identified

The 12 failing tests have a **fundamental design flaw**: they expect all frameworks to implement ml4t.backtest's "close on next entry" behavior, which is **strategy-specific logic**, not universal framework behavior.

**ml4t.backtest Strategy Logic** (`engine_wrappers.py:133`):
```python
# Exit logic (explicit exit signal OR new entry while holding position)
should_exit = (exit_signal and current_qty != 0) or (entry_signal and current_qty != 0)
```

**VectorBT's Limitation**: Cannot execute both exit+entry on the same bar due to conflict resolution (`resolve_signal_conflict_nb` in VectorBT source). When conflict occurs, VectorBT chooses **either** exit OR entry, not both sequentially.

**Evidence**:
- Read VectorBT source: `resources/vectorbt.pro-main/vectorbtpro/portfolio/nb/from_signals.py:134-196`
- `upon_long_conflict='exit'` makes VectorBT **ignore** the entry signal when both entry+exit occur (line 163-165)
- No VectorBT parameter supports "exit THEN re-enter on same bar"

## Recent Decisions

1. **Wrapper Fix Strategy**: Generate exit signals **one bar before** each subsequent entry to avoid VectorBT's conflict resolution entirely
2. **Test Design Flaw**: These validation tests incorrectly assume all frameworks have identical execution models
3. **Proper Fix Required**: Tests should provide **explicit exit signals** rather than expecting wrappers to invent them

## 12 Failing Tests (All Have Same Root Cause)

Tests expecting "hold until next entry" behavior without providing explicit exits:

1. `test_1_1_baseline_entries.py` - Entry signals only, expects 19 trades
2. `test_2_2_combined_fees.py` - Combined fee validation
3. `test_3_1_fixed_slippage.py` - Fixed slippage validation
4. `test_3_2_percentage_slippage.py` - Percentage slippage validation
5. `test_3_3_combined_costs.py` - Combined costs validation
6. `test_all_platforms_scenario_001.py` - Multi-platform scenario
7. `test_extractors.py::test_backtest_empty_results` - Empty results handling
8-10. `test_integrated_framework_alignment.py` - 3 alignment tests
11. `test_pytest_integration.py::test_backtest_vectorbt_agreement` - Agreement test
12. `test_validation.py::test_full_validation` - Full validation test

**Common Pattern**: All pass `exits=None` to wrappers and expect frameworks to close positions on next entry.

## Next Steps

### Option 1: Update Test Expectations (Quick Fix)
Modify failing tests to accept ~0.6% PnL variance as acceptable given different execution models.

**Pros**: Fast, acknowledges framework differences
**Cons**: Doesn't fix the design flaw, may hide real bugs

### Option 2: Fix Test Design (Proper Fix)
Modify test helper functions to generate explicit exit signals one bar before each subsequent entry.

**Location**: `tests/validation/common/__init__.py` or test files
**Change**: When test expects "close on next entry", generate explicit exits array
**Impact**: Tests become framework-agnostic, expectations are explicit

**Example**:
```python
def generate_close_on_next_entry_exits(entries, n_bars):
    """Generate exit signals one bar before each subsequent entry."""
    exits = pd.Series([False] * n_bars)
    entry_indices = entries[entries].index.tolist()

    for i in range(1, len(entry_indices)):
        exit_idx = entry_indices[i] - 1
        if exit_idx >= 0:
            exits.iloc[exit_idx] = True

    return exits
```

Then update tests:
```python
# OLD:
results = wrapper.run_backtest(ohlcv, entries, exits=None, config=config)

# NEW:
exits = generate_close_on_next_entry_exits(entries, len(ohlcv))
results = wrapper.run_backtest(ohlcv, entries, exits=exits, config=config)
```

### Option 3: Document Limitation (Minimal Fix)
Update README.md to document that "hold until next entry" tests have known ~0.6% variance due to framework execution model differences.

## Key Files Modified

1. **tests/validation/conftest.py** (CREATED) - Auto-skip when dependencies missing
2. **tests/validation/README.md** (UPDATED) - Status updated to 91% passing, 12 failures documented
3. **tests/validation/common/engine_wrappers.py:290-302** (FIXED) - VectorBT exit signal generation

## Deleted Files (Obsolete)

1. `tests/validation/test_qengine_signal_processing.py` - Used removed MarketEvent API
2. `tests/validation/test_diagnostic_with_logging.py` - Used old event classes
3. `tests/validation/test_2_3_asset_specific_fees.py` - Used old event-driven API

## Virtual Environments

- **`.venv`**: Main environment (no comparison frameworks)
- **`.venv-validation`**: Has VectorBT Pro 2025.7.27, Backtrader, Zipline
- **Python**: 3.12.11 (downgraded from 3.13.5)

**Test Command**:
```bash
source .venv-validation/bin/activate && pytest tests/validation/ -q --tb=no
```

## Investigation Resources

**VectorBT Source Code** (all available locally):
- Conflict resolution: `resources/vectorbt.pro-main/vectorbtpro/portfolio/nb/from_signals.py:134-196`
- Portfolio API: `resources/vectorbt.pro-main/vectorbtpro/portfolio/base.py`
- Enums: `resources/vectorbt.pro-main/vectorbtpro/portfolio/enums.py`

**Backtrader Source**: `resources/backtrader-master/backtrader/brokers/bbroker.py`
**Zipline Source**: `resources/zipline-reloaded-main/src/zipline/`

## Branch & Git Status

**Branch**: `feature/phase-1-ml-data-foundation`
**Uncommitted Changes**:
```
M tests/validation/README.md
M tests/validation/common/engine_wrappers.py
?? .claude/transitions/2025-11-21/
```

**Recent Commits**:
```
6c7f8d0 fix: Update validation tests to use new ml4t.backtest API
8e71680 fix: Fix import paths in runner.py for new modular API structure
```

## Open Questions

1. Should we accept ~0.6% PnL variance as "good enough" for validation tests?
2. Should tests be redesigned to provide explicit exit signals?
3. Is there a way to make VectorBT execute exit+entry on same bar without conflicts?

## Debugging Context

**Key Learning**: VectorBT's `upon_long_conflict` parameter does NOT support "exit then re-enter" - it chooses one signal to process when both occur on same bar.

**Tried Approaches**:
1. ❌ `upon_long_conflict='exit'` - Ignores entry, processes only exit
2. ❌ `accumulate=False` - Ignores subsequent entries, doesn't close+reopen
3. ✅ **Generate exits one bar before entries** - Works, produces 20 vs 19 trades

**Why 20 vs 19 trades**: ml4t.backtest holds small final position (0.0034 BTC), VectorBT holds full position (3.4392 BTC). Different end-of-data handling.

## Session Summary

**Hours Spent**: ~3 hours
**Major Discovery**: Validation tests have fundamental design flaw - assume all frameworks share ml4t.backtest's execution model
**Blocker**: Cannot make VectorBT match ml4t.backtest exactly without redesigning tests to provide explicit exits

**Recommendation**: Implement Option 2 (Fix Test Design) for long-term correctness, or Option 1 (Update Expectations) for quick resolution.

---

**Working Directory**: `/home/stefan/ml4t/software/backtest/`
**Last Test Run**: 142 passed, 12 failed, 2 skipped (198s)
**Git Branch**: `feature/phase-1-ml-data-foundation`
