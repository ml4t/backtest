# Handoff: 2025-11-04 12:14:55 UTC

## Active Work

**Building Clean Validation Framework for Cross-Platform Backtest Comparison**

Moving validation work from complex crypto_futures project into clean testbed in backtest library (`tests/validation/`). Goal: Validate qengine trading mechanics against VectorBT Pro, Backtrader, and Zipline using controlled scenarios with pre-defined signals.

## Current State

### âœ… Completed

1. **Architecture Designed**
   - `tests/validation/VALIDATION_ARCHITECTURE.md` - Overall framework
   - `tests/validation/TRADE_COMPARISON_DESIGN.md` - Trade-by-trade comparison approach
   - `tests/validation/STATUS.md` - Implementation status

2. **Core Implementation**
   - `tests/validation/core/trade.py` - StandardTrade dataclass âœ… TESTED
     - Platform-independent trade representation
     - Entry/exit timestamps, prices, OHLC components
     - Helper functions: `get_bar_at_timestamp()`, `infer_price_component()`

3. **Basic Infrastructure**
   - `tests/validation/scenarios/scenario_001_simple_market_orders.py` - 4 hardcoded signals âœ…
   - `tests/validation/runner.py` - Cross-platform executor with SimpleDataFeed âœ…
   - qengine adapter working (2 trades, $2,972.53 P&L) âœ…
   - VectorBT adapter working (2 trades, $36,289.27 P&L) âœ…

### ðŸ”´ Critical User Feedback

**"You may never just compare trade counts. That is such a high-level metric that it's almost meaningless."**

Must drill down to:
1. **Entry/exit timestamps** - exact timing comparison
2. **Entry/exit prices** - which OHLC component used (open/close/high/low)
3. **Fees & slippage** - how calculated
4. **Trade-by-trade matching** - never aggregate statistics

User specifically mentioned crypto_futures project has proper trade reporting built into qengine for exactly this purpose.

## Recent Decisions

### Design Philosophy
- **Signals as INPUT**: Never compute signals in test scenarios, always pre-defined
- **Trade-by-trade comparison**: No aggregate metrics, must compare individual trades
- **StandardTrade format**: All platforms convert to common format for comparison
- **OHLC component identification**: Infer which component (open/close) was used for execution

### Architecture Choices
- **Location**: `backtest/tests/validation/` (not in projects/)
- **Structure**: scenarios/ + extractors/ + comparison/ + runner.py
- **Platforms**: qengine, VectorBT, Backtrader, Zipline (all 4)
- **Start simple**: Scenario 001 with 4 market orders, no stops/limits

### Technical Fixes Applied
- Fixed SimpleDataFeed to implement all abstract methods (peek_next_timestamp, reset, seek)
- Fixed qengine imports (MarketDataType, OrderType from core.types)
- Fixed commission model (PercentageCommission instead of direct parameter)
- Fixed datetime objects (pandas date_range instead of polars to avoid date vs datetime issue)

## Active Challenges

### 1. Large P&L Discrepancy (12x difference)
- **qengine**: $2,972.53 (matches manual calculation $2,976.07)
- **VectorBT**: $36,289.27 (12x higher!)
- **Not yet diagnosed**: Need trade-by-trade comparison to understand
- **Likely causes**: Position sizing, execution timing, price component

### 2. Execution Model Differences (from earlier crypto_futures work)
From previous investigation (see `projects/crypto_futures/.claude/memory/`):
- **VectorBT**: Same-bar execution (signal at T â†’ fill at T close)
- **qengine**: Next-bar execution (signal at T â†’ fill at T+1 open)
- This explains timing differences but not 12x P&L difference

### 3. Trade Extraction Not Implemented Yet
Currently runner.py has inline trade matching logic. Need to extract into:
- `extractors/qengine.py` - Match BUY/SELL orders into complete trades
- `extractors/vectorbt.py` - Parse portfolio.trades.records_readable
- Must include OHLC lookup and component identification

## Next Steps

### Immediate (2-3 hours)

1. **Implement Extractors** (`tests/validation/extractors/`)
   ```python
   # extractors/qengine.py
   def extract_qengine_trades(results: dict, data: pl.DataFrame) -> List[StandardTrade]:
       # Match BUY/SELL into complete trades
       # Look up OHLC bars at entry/exit
       # Infer price component (open/close/high/low)
       # Return List[StandardTrade]

   # extractors/vectorbt.py
   def extract_vectorbt_trades(portfolio, data: pd.DataFrame) -> List[StandardTrade]:
       # Parse portfolio.trades.records_readable
       # Has 'Entry Index', 'Exit Index', 'Avg Entry Price', etc.
       # Look up OHLC and infer components
       # Return List[StandardTrade]

   # extractors/backtrader.py
   def extract_backtrader_trades(...) -> List[StandardTrade]:
       # Parse Backtrader analyzer results

   # extractors/zipline.py
   def extract_zipline_trades(...) -> List[StandardTrade]:
       # Parse Zipline performance DataFrame
   ```

2. **Implement Trade Matcher** (`tests/validation/comparison/matcher.py`)
   ```python
   @dataclass
   class TradeMatch:
       # One StandardTrade per platform (or None if missing)
       qengine_trade: StandardTrade | None
       vectorbt_trade: StandardTrade | None
       backtrader_trade: StandardTrade | None
       zipline_trade: StandardTrade | None

       # Comparison results
       entry_timestamp_match: dict[str, bool]
       entry_price_diff: dict[str, float]  # % difference
       entry_components: dict[str, str]    # 'open'/'close'/etc
       # ... same for exit

   def match_trades(trades_by_platform: dict) -> List[TradeMatch]:
       # Primary key: entry_timestamp (with 60s tolerance)
       # Return list of matched trades
   ```

3. **Implement Reporter** (`tests/validation/comparison/reporter.py`)
   ```python
   def generate_trade_report(match: TradeMatch) -> str:
       # Show entry timing, prices, components across all platforms
       # Show exit timing, prices, components
       # Show P&L breakdown with commission/slippage
       # Verdict: match/mismatch/explained
   ```

4. **Update runner.py** to use extractors + matcher + reporter

### After Extractors Working

5. **Run Scenario 001** with all 4 platforms
6. **Generate detailed comparison report** showing exactly where differences are
7. **Document execution model differences** in validation docs
8. **Create Scenario 002** (limit orders) once basic flow works

## Session Context

### Working Directory
```
/home/stefan/ml4t/software/backtest/tests/validation/
```

### Key Files Created This Session
- `VALIDATION_ARCHITECTURE.md` - Overall design
- `TRADE_COMPARISON_DESIGN.md` - Detailed comparison approach
- `STATUS.md` - Implementation tracking
- `core/__init__.py` + `core/trade.py` - StandardTrade + helpers âœ… TESTED
- `scenarios/scenario_001_simple_market_orders.py` - First test case âœ…
- `runner.py` - Working executor (needs refactor to use extractors)

### Commands to Run Validation
```bash
cd /home/stefan/ml4t/software/backtest/tests/validation

# Test qengine only
uv run python runner.py --scenario 001 --platforms qengine

# Test qengine vs VectorBT
uv run python runner.py --scenario 001 --platforms qengine,vectorbt

# Once all platforms ready
uv run python runner.py --scenario 001 --platforms qengine,vectorbt,backtrader,zipline
```

### Current Test Output (High-Level - NEEDS DRILL-DOWN)
```
Platform        Trades   Total PnL       Time       Status
---------------------------------------------------------------
qengine         2        $2,972.53       0.243s     âœ… OK
vectorbt        2        $36,289.27      1.249s     âœ… OK
```

**Trade count matches but P&L differs by 12x** - This is exactly why we need trade-by-trade comparison!

## Related Work (Context from Earlier Sessions)

### crypto_futures Project Investigation
Located at: `/home/stefan/ml4t/software/projects/crypto_futures/`

**Key learnings** (read these for context):
- `.claude/memory/vectorbt_validation_complete.md` - VectorBT has volume filter bug
- `.claude/memory/vectorbt_benchmark_approach.md` - Using VectorBT as benchmark
- `docs/vectorbt_entry_price_analysis.md` - Entry price determination
- `scripts/compare_exact_matching.py` - Trade matching by timestamp

**Trade format from qengine broker** (`src/qengine/execution/broker.py:get_trades()`):
```python
{
    'order_id': str,
    'asset_id': str,
    'side': 'buy'/'sell',  # lowercase!
    'quantity': float,
    'price': float,
    'commission': float,
    'status': str,
    'submitted_time': datetime,
    'filled_time': datetime,
}
```

**Challenge**: qengine returns individual orders, must match BUYâ†’SELL into complete trades.

**VectorBT format** (`portfolio.trades.records_readable`):
```python
{
    'Entry Index': Timestamp,      # Entry datetime
    'Exit Index': Timestamp,       # Exit datetime
    'Avg Entry Price': float,
    'Avg Exit Price': float,
    'Size': float,                 # Quantity
    'PnL': float,
    'Entry Fees': float,
    'Exit Fees': float,
    'Direction': 'Long'/'Short',
    'Status': 'Closed'/'Open',
}
```

**Challenge**: Need to infer which OHLC component was used (likely close for same-bar).

## Important Context from User

1. **From crypto_futures work**: "We added trade reporting capabilities to BackTest precisely for that reason, to make it easy to compare."

2. **User emphasis**: Must compare:
   - Entry/exit timestamps (not just counts)
   - Entry/exit prices (with OHLC component)
   - Fees and slippage details

3. **User instruction**: "start with simple scenarios, but do add backtrader & zipline. then build out the scenarios. we need our own, well architected testbed here for this. ultrathink about how to set this up properly, don't just muddle through."

## Open Questions

1. **Backtrader integration** - What's the API for getting trades from Backtrader?
2. **Zipline integration** - What's the format of Zipline performance DataFrame?
3. **Position sizing** - Why does VectorBT P&L differ by 12x? Wrong quantity somewhere?
4. **Report format** - Text sufficient or need HTML?

## Files to Review Before Continuing

1. `tests/validation/TRADE_COMPARISON_DESIGN.md` - Detailed extractor/matcher/reporter design
2. `tests/validation/core/trade.py` - StandardTrade implementation (working)
3. `tests/validation/STATUS.md` - Current status and next steps
4. `projects/crypto_futures/scripts/compare_exact_matching.py` - Example of timestamp matching

## Git Status

Currently in: `/home/stefan/ml4t/software/backtest/`

New files created (not committed):
- `tests/validation/VALIDATION_ARCHITECTURE.md`
- `tests/validation/TRADE_COMPARISON_DESIGN.md`
- `tests/validation/STATUS.md`
- `tests/validation/core/__init__.py`
- `tests/validation/core/trade.py`
- `tests/validation/scenarios/scenario_001_simple_market_orders.py`
- `tests/validation/runner.py`

Modified files:
- `tests/validation/adapters/vectorbt_adapter.py` (previous validation work)
- `tests/validation/adapters/qengine_adapter.py` (previous validation work)

## Memory Updates Needed

Once extractors are working and first full comparison complete, update:
- `.claude/memory/validation_approach.md` - Document the StandardTrade + extractor pattern
- `.claude/memory/execution_models.md` - Document same-bar vs next-bar differences across platforms

---

**To Continue:**
1. Run `/clear`
2. Say: `continue from .claude/transitions/2025-11-04/121455.md`

**First task**: Implement `tests/validation/extractors/qengine.py` to convert broker results into List[StandardTrade]
